
@article{journals/corr/abs-1301-3781,
  added-at = {2013-10-23T23:02:12.000+0200},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  biburl = {https://www.bibsonomy.org/bibtex/29665b85e8756834ac29fcbd2c6ad0837/wool},
  ee = {http://arxiv.org/abs/1301.3781},
  interhash = {e92df552b17e9f952226a893b84ad739},
  intrahash = {9665b85e8756834ac29fcbd2c6ad0837},
  journal = {CoRR},
  keywords = {nlp},
  timestamp = {2013-10-23T23:02:12.000+0200},
  title = {Efficient Estimation of Word Representations in Vector Space},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1301.html#abs-1301-3781},
  volume = {abs/1301.3781},
  year = 2013
}

@misc{wu2017starspace,
  abstract = {We present StarSpace, a general-purpose neural embedding model that can solve
a wide variety of problems: labeling tasks such as text classification, ranking
tasks such as information retrieval/web search, collaborative filtering-based
or content-based recommendation, embedding of multi-relational graphs, and
learning word, sentence or document level embeddings. In each case the model
works by embedding those entities comprised of discrete features and comparing
them against each other -- learning similarities dependent on the task.
Empirical results on a number of tasks show that StarSpace is highly
competitive with existing methods, whilst also being generally applicable to
new cases where those methods are not.},
  added-at = {2017-09-16T15:07:22.000+0200},
  author = {Wu, Ledell and Fisch, Adam and Chopra, Sumit and Adams, Keith and Bordes, Antoine and Weston, Jason},
  biburl = {https://www.bibsonomy.org/bibtex/267aa5262d32b09a79e591e516b55d329/crack521},
  description = {StarSpace: Embed All The Things!},
  interhash = {e83438f3dcdc19a3db05153e58a5c6b6},
  intrahash = {67aa5262d32b09a79e591e516b55d329},
  keywords = {deep_learning embedding},
  note = {cite arxiv:1709.03856},
  timestamp = {2017-09-16T15:07:22.000+0200},
  title = {StarSpace: Embed All The Things!},
  url = {http://arxiv.org/abs/1709.03856},
  year = 2017
}

@misc{barkan2016item2vec,
  abstract = {Many Collaborative Filtering (CF) algorithms are item-based in the sense that
they analyze item-item relations in order to produce item similarities.
Recently, several works in the field of Natural Language Processing suggested
to learn a latent representation of words using neural embedding algorithms.
Among them, the Skip-gram with Negative Sampling (SGNS), also known as
Word2Vec, was shown to provide state-of-the-art results on various linguistics
tasks. In this paper, we show that item-based CF can be cast in the same
framework of neural word embedding. Inspired by SGNS, we describe a method we
name Item2Vec for item-based CF that produces embedding for items in a latent
space. The method is capable of inferring item-to-item relations even when user
information is not available. We present experimental results on large scale
datasets that demonstrate the effectiveness of the Item2Vec method and show it
is competitive with SVD.},
  added-at = {2016-07-12T17:28:32.000+0200},
  author = {Barkan, Oren and Koenigstein, Noam},
  biburl = {https://www.bibsonomy.org/bibtex/209fc26edc98def6dae607580b4c71b86/thoni},
  description = {Item2Vec: Neural Item Embedding for Collaborative Filtering},
  interhash = {14c994323f4ab2583aa840da718720e0},
  intrahash = {09fc26edc98def6dae607580b4c71b86},
  keywords = {collaborative embedding filtering item2vec},
  note = {cite arxiv:1603.04259},
  timestamp = {2016-11-02T06:50:19.000+0100},
  title = {Item2Vec: Neural Item Embedding for Collaborative Filtering},
  url = {http://arxiv.org/abs/1603.04259},
  year = 2016
}

@inproceedings{journals/jmlr/GutmannH10,
  added-at = {2019-05-29T00:00:00.000+0200},
  author = {Gutmann, Michael and Hyvärinen, Aapo},
  biburl = {https://www.bibsonomy.org/bibtex/225d18c731a7137f5f21bf14497ad6ca2/dblp},
  booktitle = {AISTATS},
  crossref = {conf/aistats/2010},
  editor = {Teh, Yee Whye and Titterington, D. Mike},
  ee = {http://proceedings.mlr.press/v9/gutmann10a.html},
  interhash = {c6750862edf4ecded936b5c5477aabe9},
  intrahash = {25d18c731a7137f5f21bf14497ad6ca2},
  keywords = {dblp},
  pages = {297-304},
  publisher = {JMLR.org},
  series = {JMLR Proceedings},
  timestamp = {2019-05-30T11:50:49.000+0200},
  title = {Noise-contrastive estimation: A new estimation principle for unnormalized statistical models.},
  url = {http://dblp.uni-trier.de/db/journals/jmlr/jmlrp9.html#GutmannH10},
  volume = 9,
  year = 2010
}

@inproceedings{conf/icml/MnihT12,
  added-at = {2019-04-03T00:00:00.000+0200},
  author = {Mnih, Andriy and Teh, Yee Whye},
  biburl = {https://www.bibsonomy.org/bibtex/29d5d6d4ce889849ceaf602aa612a6c2a/dblp},
  booktitle = {ICML},
  crossref = {conf/icml/2012},
  ee = {http://icml.cc/2012/papers/855.pdf},
  interhash = {f4c9c0e2707260c93f6975c7939a70f4},
  intrahash = {9d5d6d4ce889849ceaf602aa612a6c2a},
  keywords = {dblp},
  publisher = {icml.cc / Omnipress},
  timestamp = {2019-04-04T11:48:04.000+0200},
  title = {A fast and simple algorithm for training neural probabilistic language models.},
  url = {http://dblp.uni-trier.de/db/conf/icml/icml2012.html#MnihT12},
  year = 2012
}

@inproceedings{conf/emnlp/VaswaniZFC13,
  added-at = {2019-09-11T00:00:00.000+0200},
  author = {Vaswani, Ashish and Zhao, Yinggong and Fossum, Victoria and Chiang, David},
  biburl = {https://www.bibsonomy.org/bibtex/2f23380a6fa53aebb87bcdf7c109ae42e/dblp},
  booktitle = {EMNLP},
  crossref = {conf/emnlp/2013},
  ee = {https://www.aclweb.org/anthology/D13-1140/},
  interhash = {a7829efd7bfa6170d45d7244d0732280},
  intrahash = {f23380a6fa53aebb87bcdf7c109ae42e},
  isbn = {978-1-937284-97-8},
  keywords = {dblp},
  pages = {1387-1392},
  publisher = {ACL},
  timestamp = {2019-09-14T11:48:51.000+0200},
  title = {Decoding with Large-Scale Neural Language Models Improves Translation.},
  url = {http://dblp.uni-trier.de/db/conf/emnlp/emnlp2013.html#VaswaniZFC13},
  year = 2013
}

@inproceedings{conf/naacl/ZophVMK16,
  added-at = {2020-01-28T00:00:00.000+0100},
  author = {Zoph, Barret and Vaswani, Ashish and May, Jonathan and Knight, Kevin},
  biburl = {https://www.bibsonomy.org/bibtex/2dd0798e1535f168b151a25297b48174a/dblp},
  booktitle = {HLT-NAACL},
  crossref = {conf/naacl/2016},
  editor = {Knight, Kevin and Nenkova, Ani and Rambow, Owen},
  ee = {https://www.aclweb.org/anthology/N16-1145/},
  interhash = {4af7c539debfea71dc11bf639d203873},
  intrahash = {dd0798e1535f168b151a25297b48174a},
  isbn = {978-1-941643-91-4},
  keywords = {dblp},
  pages = {1217-1222},
  publisher = {The Association for Computational Linguistics},
  timestamp = {2020-01-29T11:47:15.000+0100},
  title = {Simple, Fast Noise-Contrastive Estimation for Large RNN Vocabularies.},
  url = {http://dblp.uni-trier.de/db/conf/naacl/naacl2016.html#ZophVMK16},
  year = 2016
}

@incollection{mikolov2013distributed,
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several improvements that make the Skip-gram model more expressive and enable it to learn higher quality vectors more rapidly. We show that by subsampling frequent words we obtain significant speedup, and also learn higher quality representations as measured by our tasks. We also introduce Negative Sampling, a simplified variant of Noise Contrastive Estimation (NCE) that learns more accurate vectors for frequent words compared to the hierarchical softmax. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of Canada'' and "Air'' cannot be easily combined to obtain "Air Canada''. Motivated by this example, we present a simple and efficient method for finding phrases, and show that their vector representations can be accurately learned by the Skip-gram model.},
  added-at = {2014-01-29T14:16:06.000+0100},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  biburl = {https://www.bibsonomy.org/bibtex/2f310b01a7363a94322e180ecd249bec0/jaeschke},
  booktitle = {Advances in Neural Information Processing Systems 26},
  editor = {Burges, C.J.C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K.Q.},
  interhash = {4d7ff49f008ec05928f11e50f2db1cf9},
  intrahash = {f310b01a7363a94322e180ecd249bec0},
  keywords = {distribution language learning nlp representation similarity skip-gram word},
  pages = {3111--3119},
  timestamp = {2014-07-28T15:57:31.000+0200},
  title = {Distributed Representations of Words and Phrases and their Compositionality},
  url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality},
  year = 2013
}

@misc{goldberg2014word2vec,
  abstract = {The word2vec software of Tomas Mikolov and colleagues
(https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and
provides state-of-the-art word embeddings. The learning models behind the
software are described in two research papers. We found the description of the
models in these papers to be somewhat cryptic and hard to follow. While the
motivations and presentation may be obvious to the neural-networks
language-modeling crowd, we had to struggle quite a bit to figure out the
rationale behind the equations.
  This note is an attempt to explain equation (4) (negative sampling) in
"Distributed Representations of Words and Phrases and their Compositionality"
by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.},
  added-at = {2016-05-31T15:34:46.000+0200},
  author = {Goldberg, Yoav and Levy, Omer},
  biburl = {https://www.bibsonomy.org/bibtex/2d03ee2d89572258e9951a2058b333312/albinzehe},
  description = {[1402.3722] word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
  interhash = {529718927f289e07d24eb4b9b4d4e207},
  intrahash = {d03ee2d89572258e9951a2058b333312},
  keywords = {ma-zehe thema:word_embeddings word2vec wordembeddings},
  note = {cite arxiv:1402.3722},
  timestamp = {2016-10-24T11:33:25.000+0200},
  title = {word2vec Explained: deriving Mikolov et al.'s negative-sampling
  word-embedding method},
  url = {http://arxiv.org/abs/1402.3722},
  year = 2014
}

@inproceedings{devlin2014robust,
  added-at = {2017-11-16T13:18:29.000+0100},
  address = {Baltimore, Maryland},
  author = {Devlin, Jacob and Zbib, Rabih and Huang, Zhongqiang and Lamar, Thomas and Schwartz, Richard and Makhoul, John},
  biburl = {https://www.bibsonomy.org/bibtex/20cc81b9228ac769863a3dc243f6229d2/slicside},
  booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  description = {Nur für Referenzzwecke verwendet (als Referenz verwendet, dass RNNs für die maschinelle Übersetzung verwendet werden können).},
  interhash = {7f72d1bfd29f22c18e0cb32084c41734},
  intrahash = {0cc81b9228ac769863a3dc243f6229d2},
  keywords = {dropout final uw_ws17_ml},
  month = {June},
  pages = {1370--1380},
  publisher = {Association for Computational Linguistics},
  timestamp = {2017-12-14T18:11:37.000+0100},
  title = {Fast and Robust Neural Network Joint Models for Statistical Machine Translation},
  url = {http://www.aclweb.org/anthology/P14-1129},
  year = 2014
}

@inproceedings{conf/naacl/AndreasK15,
  added-at = {2020-01-28T00:00:00.000+0100},
  author = {Andreas, Jacob and Klein, Dan},
  biburl = {https://www.bibsonomy.org/bibtex/22cdade8c17e13b3142722091cd93fd81/dblp},
  booktitle = {HLT-NAACL},
  crossref = {conf/naacl/2015},
  editor = {Mihalcea, Rada and Chai, Joyce Yue and Sarkar, Anoop},
  ee = {https://www.aclweb.org/anthology/N15-1027/},
  interhash = {ad171a317594dd6d8b12c1cadbcf09cd},
  intrahash = {2cdade8c17e13b3142722091cd93fd81},
  isbn = {978-1-941643-49-5},
  keywords = {dblp},
  pages = {244-249},
  publisher = {The Association for Computational Linguistics},
  timestamp = {2020-01-29T11:47:29.000+0100},
  title = {When and why are log-linear models self-normalizing?},
  url = {http://dblp.uni-trier.de/db/conf/naacl/naacl2015.html#AndreasK15},
  year = 2015
}
